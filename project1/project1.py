import sys
import scipy.special
import numpy as np
import networkx as nx
import csv
from dash import Dash, html
import dash_cytoscape as cyto
import matplotlib.pyplot as plt
import pandas as pd


def inneighbors(G, i):
    """Helper function for finding the parents of a variable."""
    return list(G.predecessors(i))

def prior(vars, G):
    """Algorithm 4.2 - Page 81 of the book.
    that this function returns takes the
    same form as the statistics generated by algorithm 4.1. To determine
    the appropriate dimensions, the
    function takes as input the list of
    variables vars and structure G."""

    n = len(vars)
    r = [vars[i].r for i in range(n)]
    q = np.array([np.prod(np.array([r[j] for j in inneighbors(G,i)])) for i in range(n)], dtype=int)
    return [np.ones(([q[i], r[i]])) for i in range(n)]

def sub2ind(siz, x):
    """Algorithm 4.1. - Page 75 of the book - Helper function."""
    return np.ravel_multi_index(x, siz)

def statistics(vars, G, D):
    """Algorithm 4.1. - Page 75 of the book.
    A function for extracting the statistics, or counts,
    from a discrete data set D, assuming a Bayesian network with variables vars and structure G. The
    data set is an n x m matrix, where
    n is the number of variables and
    m is the number of data points.
    This function returns an array M of
    length n. The ith component consists of a qi x ri matrix of counts.
    The sub2ind(siz, x) function returns a linear index into an array
    with dimensions specified by siz
    given coordinates x. It is used to
    identify which parental instantiation is relevant to a particular data
    point and variable."""

    n = len(vars)
    r = np.array([vars[i].r for i in range(n)])
    q = np.array([np.prod(np.array([r[j] for j in inneighbors(G,i)])) for i in range(n)], dtype=int)
    M = [np.zeros((q[i], r[i])) for i in range(n)]
    for index, row in D.iterrows():
        row = np.array(row)
        for i in range(n):
            k = row[i] - 1 # value of variable i
            parents = inneighbors(G,i)
            j = 0
            if len(parents) > 0: # if i has parents
                j = sub2ind(r[parents], row[parents] - 1)
            M[i][j,k] += 1
    return M

def bayesian_score_component(M, alpha):
    """Algorithm 5.1 - Page 98 of the book - Helper function."""
    p = np.sum(scipy.special.loggamma(alpha + M))
    p -= np.sum(scipy.special.loggamma(alpha))
    p += np.sum(scipy.special.loggamma(np.sum(alpha, axis=1)))
    p -= np.sum(scipy.special.loggamma(np.sum(alpha, axis=1) + np.sum(M, axis=1)))
    return p

def bayesian_score(vars, G, D):
    """Algorithm 5.1 - Page 98 of the book.
    for computing the Bayesian score
    for a list of variables vars and
    a graph G given data D. This
    method uses a uniform prior
    αijk = 1 for all i, j, and k
    as generated by algorithm 4.2.
    The loggamma function is provided
    by SpecialFunctions.jl. Chapter 4 introduced the statistics
    and prior functions. Note that
    log(Γ(α)/Γ(α + m)) = log Γ(α) −
    log Γ(α + m), and that log Γ(1) =
    0."""

    n = len(vars)
    M = statistics(vars, G, D)
    alpha = prior(vars, G)
    return np.sum(np.array([bayesian_score_component(M[i], alpha[i]) for i in range(n)]))

class Variable:
    def __init__(self, name, r):
        self.name = name
        self.r = r

def compute(infile, outfile):
    df = pd.read_csv(infile, delimiter=',')
    df_max = df.max()
    var_names = list(df.columns)
    vars = [Variable(var_names[i], df_max[i]) for i in range(len(var_names))]
    
    # JUST FOR TESTING
    G = nx.DiGraph()
    for i in range(len(vars)): G.add_node(i)
    for i in range(3): G.add_edge(2*i, 2*i+1)
    G = k2([i for i in range(len(vars))], vars, df, max_parents=2)
    
    alpha = prior(vars, G)
    M = statistics(vars, G, df)

    print("Bayesian score: {}".format(bayesian_score(vars, G, df)))
    print("Prior: {}".format(alpha))
    print("Statistics: {}".format(M))



# K2 algorithm
def k2(ordering, vars, df, max_parents=2):
    G = nx.DiGraph()
    G.add_nodes_from(list(range(len(ordering))))
    for (k, i) in enumerate(ordering[1:]):
        y = bayesian_score(vars, G, df)
        while True:
            y_best, j_best = -np.inf, 0
            for j in ordering[:k]:
                if not G.has_edge(j, i):
                    G.add_edge(j, i)
                    y_prime = bayesian_score(vars, G, df)
                    if y_prime > y_best:
                        y_best, j_best = y_prime, j
                    G.remove_edge(j, i)
            if y_best > y:
                y = y_best
                G.add_edge(j_best, i)
            else:
                break
    return G



def main():
    if len(sys.argv) != 3:
        raise Exception("usage: python project1.py <infile>.csv <outfile>.gph")

    inputfilename = sys.argv[1]
    outputfilename = sys.argv[2]
    compute(inputfilename, outputfilename)


if __name__ == '__main__':
    main()
